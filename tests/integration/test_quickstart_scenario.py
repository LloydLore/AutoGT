"""
Integration test for quickstart scenario (Sample Vehicle TARA) per complete workflow.

This test validates the exact quickstart tutorial scenario from quickstart.md:
- Sample Vehicle TARA with specific vehicle system assets
- Complete 8-step TARA workflow validation
- Performance benchmarks and compliance verification
- Export validation with expected output formats
- Error handling and user experience validation

Test Scenario: Complete quickstart.md tutorial from start to finish
"""

import json
import pytest
import tempfile
import time
from pathlib import Path

from autogt.cli.main import cli
from click.testing import CliRunner


class TestQuickstartScenario:
    """Complete quickstart scenario integration test."""
    
    @pytest.fixture
    def runner(self):
        """CLI test runner."""
        return CliRunner()
    
    @pytest.fixture
    def quickstart_vehicle_csv(self):
        """Exact vehicle system CSV from quickstart.md."""
        # This matches exactly the CSV from quickstart.md lines 52-58
        csv_content = """Asset Name,Asset Type,Criticality Level,Interfaces,Description
ECU Gateway,HARDWARE,HIGH,"CAN,Ethernet",Central communication hub
Infotainment System,SOFTWARE,MEDIUM,"Bluetooth,WiFi,USB",Entertainment and navigation
Telematics Unit,HARDWARE,HIGH,"Cellular,GPS",Remote connectivity
Engine Control Module,HARDWARE,VERY_HIGH,CAN,Engine management system
OBD-II Port,HARDWARE,MEDIUM,OBD,Diagnostic interface"""
        
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            f.write(csv_content)
            return f.name
    
    def test_complete_quickstart_workflow(self, runner, quickstart_vehicle_csv):
        """
        Test complete quickstart scenario per quickstart.md workflow.
        
        This test follows the exact steps from quickstart.md:
        - Step 2: Create New Analysis (lines 62-77)
        - Step 3: Define Assets (lines 79-119) 
        - Step 4: Rate Impact Levels (lines 121-138)
        - Step 5: Identify Threat Scenarios (lines 140-175)
        - Step 6: Analyze Attack Paths (lines 177-189)
        - Step 7: Rate Attack Feasibility (lines 191-207)
        - Step 8: Calculate Risk Values (lines 209-245)
        - Step 9: Make Treatment Decisions (lines 247-266)
        - Step 10: Set Cybersecurity Goals (lines 268-284)
        - Step 11: Export Results (lines 286-307)
        """
        workflow_start = time.time()
        
        # Step 2: Create New Analysis (quickstart.md lines 62-77)
        print("🚀 Starting quickstart scenario: Sample Vehicle TARA")
        
        result = runner.invoke(cli, [
            'analysis', 'create',
            '--name', 'Sample Vehicle TARA',
            '--vehicle-model', 'Test Vehicle 2025',
            quickstart_vehicle_csv
        ])
        
        assert result.exit_code == 0, f"Analysis creation failed: {result.output}"
        
        analysis_data = json.loads(result.output)
        analysis_id = analysis_data['analysis_id']
        
        # Validate expected output structure from quickstart.md
        assert analysis_data['analysis_name'] == 'Sample Vehicle TARA'
        assert analysis_data['status'] == 'in_progress'
        assert analysis_data['current_step'] == 1
        assert 'created_at' in analysis_data
        
        print(f"✅ Analysis created: {analysis_id}")
        
        # Step 3: Define Assets - TARA Step 1 (quickstart.md lines 79-119)
        print("📋 Step 1: Defining assets...")\n        \n        result = runner.invoke(cli, ['assets', 'define', analysis_id])\n        assert result.exit_code == 0, f"Asset definition failed: {result.output}"\n        \n        # Verify assets created per quickstart.md expected output\n        result = runner.invoke(cli, [\n            'analysis', 'show', analysis_id, '--step', '1'\n        ])\n        assert result.exit_code == 0\n        \n        step1_data = json.loads(result.output)\n        \n        # Validate expected structure from quickstart.md lines 100-119\n        assert step1_data['step'] == 1\n        assert step1_data['name'] == 'Asset Definition'\n        assert step1_data['status'] == 'completed'\n        assert step1_data['assets_count'] == 5\n        \n        # Validate specific asset from quickstart.md example (lines 105-115)\n        ecu_gateway = None\n        for asset in step1_data['assets']:\n            if asset['name'] == 'ECU Gateway':\n                ecu_gateway = asset\n                break\n        \n        assert ecu_gateway is not None, "ECU Gateway asset not found"\n        assert ecu_gateway['asset_type'] == 'HARDWARE'\n        assert ecu_gateway['criticality_level'] == 'HIGH'\n        assert 'CAN' in ecu_gateway['interfaces']\n        assert 'Ethernet' in ecu_gateway['interfaces']\n        \n        # Validate security properties (expected in real implementation)\n        if 'security_properties' in ecu_gateway:\n            security = ecu_gateway['security_properties']\n            assert 'confidentiality' in security\n            assert 'integrity' in security\n            assert 'availability' in security\n        \n        print("✅ Step 1 completed: Assets defined")\n        \n        # Step 4: Rate Impact Levels - TARA Step 2 (quickstart.md lines 121-138)\n        print("📊 Step 2: Rating impact levels...")\n        \n        result = runner.invoke(cli, ['impact', 'rate', analysis_id])\n        assert result.exit_code == 0, f"Impact rating failed: {result.output}"\n        \n        # Verify impact assessment prompts and categories per quickstart.md\n        # The system should prompt for: Safety, Financial, Operational, Privacy impacts\n        # Categories: NONE/NEGLIGIBLE, MODERATE, MAJOR, HAZARDOUS/SEVERE\n        \n        print("✅ Step 2 completed: Impact levels rated")\n        \n        # Step 5: Identify Threat Scenarios - TARA Step 3 (quickstart.md lines 140-175)\n        print("🔍 Step 3: Identifying threat scenarios with AI...")\n        \n        threat_start = time.time()\n        result = runner.invoke(cli, [\n            'threats', 'identify', '--auto-generate', analysis_id\n        ])\n        threat_duration = time.time() - threat_start\n        \n        assert result.exit_code == 0, f"Threat identification failed: {result.output}"\n        \n        # Verify threats generated per quickstart.md expected output (lines 148-175)\n        result = runner.invoke(cli, [\n            'analysis', 'show', analysis_id, '--step', '3'\n        ])\n        assert result.exit_code == 0\n        \n        step3_data = json.loads(result.output)\n        \n        # Validate AI threat generation results\n        assert step3_data['threats_identified'] >= 5, "Should identify threats for each asset"\n        \n        threat_scenarios = step3_data['threat_scenarios']\n        assert len(threat_scenarios) > 0, "Should generate threat scenarios"\n        \n        # Look for ECU Gateway threat example from quickstart.md (lines 161-170)\n        ecu_threats = [\n            t for t in threat_scenarios \n            if t['asset_name'] == 'ECU Gateway'\n        ]\n        \n        if len(ecu_threats) > 0:\n            sample_threat = ecu_threats[0]\n            \n            # Validate threat structure per quickstart.md\n            required_fields = ['threat_name', 'threat_actor', 'motivation', 'attack_vectors', 'prerequisites']\n            for field in required_fields:\n                assert field in sample_threat, f"Missing threat field: {field}"\n            \n            # Validate threat actor types per ISO/SAE 21434\n            valid_actors = ['CRIMINAL', 'NATION_STATE', 'INSIDER', 'HACKTIVIST']\n            assert sample_threat['threat_actor'] in valid_actors\n            \n            # Validate attack vectors and prerequisites are lists\n            assert isinstance(sample_threat['attack_vectors'], list)\n            assert isinstance(sample_threat['prerequisites'], list)\n        \n        print(f"✅ Step 3 completed: {len(threat_scenarios)} threats identified in {threat_duration:.2f}s")\n        \n        # Step 6: Analyze Attack Paths - TARA Step 4 (quickstart.md lines 177-189)\n        print("🛣️  Step 4: Analyzing attack paths...")\n        \n        result = runner.invoke(cli, ['attacks', 'analyze', analysis_id])\n        assert result.exit_code == 0, f"Attack path analysis failed: {result.output}"\n        \n        # Attack path analysis should identify:\n        # - Attack step sequences\n        # - Intermediate targets  \n        # - Technical barriers\n        # - Required attacker resources\n        \n        print("✅ Step 4 completed: Attack paths analyzed")\n        \n        # Step 7: Rate Attack Feasibility - TARA Step 5 (quickstart.md lines 191-207)\n        print("⚖️  Step 5: Rating attack feasibility...")\n        \n        result = runner.invoke(cli, ['feasibility', 'rate', analysis_id])\n        assert result.exit_code == 0, f"Feasibility rating failed: {result.output}"\n        \n        # Feasibility assessment per ISO/SAE 21434 criteria:\n        # - Elapsed time required\n        # - Specialist expertise needed\n        # - Knowledge of target system\n        # - Window of opportunity\n        # - Equipment required\n        \n        print("✅ Step 5 completed: Attack feasibility rated")\n        \n        # Step 8: Calculate Risk Values - TARA Step 6 (quickstart.md lines 209-245)\n        print("🎯 Step 6: Calculating risk values using ISO/SAE 21434...")\n        \n        risk_start = time.time()\n        result = runner.invoke(cli, [\n            'risks', 'calculate', '--method', 'iso21434', analysis_id\n        ])\n        risk_duration = time.time() - risk_start\n        \n        assert result.exit_code == 0, f"Risk calculation failed: {result.output}"\n        \n        # Performance validation per quickstart.md requirements\n        assert risk_duration < 60, f"Risk calculation took {risk_duration:.2f}s (>1min limit)"\n        \n        # Verify risk calculation results per quickstart.md expected output (lines 227-245)\n        result = runner.invoke(cli, [\n            'analysis', 'show', analysis_id, '--step', '6'\n        ])\n        assert result.exit_code == 0\n        \n        risk_data = json.loads(result.output)\n        \n        # Validate risk summary structure\n        assert 'risks_calculated' in risk_data\n        assert risk_data['risks_calculated'] > 0\n        \n        risk_summary = risk_data['risk_summary']\n        \n        # Validate risk level distribution per quickstart.md example\n        required_levels = ['LOW', 'MEDIUM', 'HIGH', 'VERY_HIGH']\n        for level in required_levels:\n            assert level in risk_summary, f"Missing risk level: {level}"\n        \n        total_risks = sum(risk_summary.values())\n        assert total_risks > 0, "Should have calculated risks"\n        \n        # Validate highest risk entry per quickstart.md format\n        if 'highest_risks' in risk_data and len(risk_data['highest_risks']) > 0:\n            top_risk = risk_data['highest_risks'][0]\n            \n            required_risk_fields = ['asset_name', 'threat_name', 'risk_level', 'risk_score']\n            for field in required_risk_fields:\n                assert field in top_risk, f"Missing risk field: {field}"\n            \n            assert top_risk['risk_level'] in ['HIGH', 'VERY_HIGH']\n            assert 0 <= top_risk['risk_score'] <= 1\n        \n        print(f"✅ Step 6 completed: {total_risks} risks calculated in {risk_duration:.2f}s")\n        \n        # Step 9: Make Treatment Decisions - TARA Step 7 (quickstart.md lines 247-266)\n        print("🛡️  Step 7: Making treatment decisions...")\n        \n        result = runner.invoke(cli, ['treatments', 'decide', analysis_id])\n        assert result.exit_code == 0, f"Treatment decisions failed: {result.output}"\n        \n        # Treatment options per quickstart.md:\n        # - REDUCE: Implement countermeasures\n        # - TRANSFER: Insurance or third-party\n        # - AVOID: Remove asset/functionality  \n        # - ACCEPT: Document residual risk\n        \n        print("✅ Step 7 completed: Treatment decisions made")\n        \n        # Step 10: Set Cybersecurity Goals - TARA Step 8 (quickstart.md lines 268-284)\n        print("🎯 Step 8: Setting cybersecurity goals...")\n        \n        result = runner.invoke(cli, ['goals', 'generate', analysis_id])\n        assert result.exit_code == 0, f"Cybersecurity goals failed: {result.output}"\n        \n        # Verify final analysis completion\n        result = runner.invoke(cli, [\n            'analysis', 'show', analysis_id, '--step', '8'\n        ])\n        assert result.exit_code == 0\n        \n        final_data = json.loads(result.output)\n        assert final_data['step'] == 8\n        assert final_data['status'] == 'completed'\n        \n        # Cybersecurity goals should specify:\n        # - Protection levels required\n        # - Security controls to implement  \n        # - Verification methods\n        # - Implementation phases\n        \n        print("✅ Step 8 completed: Cybersecurity goals set")\n        \n        # Step 11: Export Results (quickstart.md lines 286-307)\n        print("📤 Exporting analysis results...")\n        \n        # Test JSON export per quickstart.md\n        with tempfile.NamedTemporaryFile(suffix='.json', delete=False) as f:\n            json_output = f.name\n        \n        export_start = time.time()\n        result = runner.invoke(cli, [\n            'export', '--format', 'json', \n            '--output', json_output,\n            analysis_id\n        ])\n        export_duration = time.time() - export_start\n        \n        assert result.exit_code == 0, f"JSON export failed: {result.output}"\n        assert export_duration < 30, f"JSON export took {export_duration:.2f}s (>30s limit)"\n        \n        # Verify JSON export content per quickstart.md expected contents\n        assert Path(json_output).exists()\n        \n        with open(json_output, 'r') as f:\n            export_data = json.load(f)\n        \n        # Validate export contents per quickstart.md lines 309-327\n        expected_sections = [\n            'analysis_metadata',\n            'executive_summary', \n            'asset_inventory',\n            'threat_scenarios',\n            'risk_analysis',\n            'treatment_decisions',\n            'cybersecurity_goals'\n        ]\n        \n        for section in expected_sections:\n            # In test environment, some sections may be empty but should exist\n            if section not in export_data:\n                print(f"⚠️  Warning: Missing export section: {section}")\n        \n        # Test Excel export per quickstart.md\n        with tempfile.NamedTemporaryFile(suffix='.xlsx', delete=False) as f:\n            excel_output = f.name\n        \n        result = runner.invoke(cli, [\n            'export', '--format', 'excel',\n            '--output', excel_output,\n            analysis_id\n        ])\n        \n        if result.exit_code == 0:\n            assert Path(excel_output).exists()\n            print("✅ Excel export completed")\n        else:\n            print(f"⚠️  Excel export failed: {result.output}")\n        \n        # Test validation report per quickstart.md\n        with tempfile.NamedTemporaryFile(suffix='.html', delete=False) as f:\n            validation_output = f.name\n        \n        result = runner.invoke(cli, [\n            'validate', '--report-format', 'html',\n            '--output', validation_output,\n            analysis_id\n        ])\n        \n        if result.exit_code == 0:\n            assert Path(validation_output).exists()\n            print("✅ ISO/SAE 21434 validation report generated")\n        \n        # Overall workflow performance validation\n        workflow_duration = time.time() - workflow_start\n        assert workflow_duration < 300, f"Complete workflow took {workflow_duration:.2f}s (>5min limit)"\n        \n        print(f"🎉 Quickstart scenario completed successfully in {workflow_duration:.2f}s")\n        print(f"   - Analysis ID: {analysis_id}")\n        print(f"   - Assets: 5 automotive components")\n        print(f"   - Threats: {len(threat_scenarios) if 'threat_scenarios' in locals() else 'N/A'}")\n        print(f"   - Risks: {total_risks if 'total_risks' in locals() else 'N/A'}")\n        print(f"   - Export formats: JSON, Excel, HTML validation")\n        \n        # Cleanup\n        cleanup_files = [json_output, excel_output, validation_output]\n        for file_path in cleanup_files:\n            if Path(file_path).exists():\n                Path(file_path).unlink()\n        \n        Path(quickstart_vehicle_csv).unlink()\n        \n        return analysis_id\n    \n    def test_quickstart_error_scenarios(self, runner, quickstart_vehicle_csv):\n        """Test error handling scenarios from quickstart tutorial."""\n        # Test invalid file format (quickstart.md troubleshooting)\n        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:\n            f.write("Invalid file content")\n            invalid_file = f.name\n        \n        result = runner.invoke(cli, [\n            'analysis', 'create',\n            '--name', 'Error Test',\n            invalid_file\n        ])\n        \n        # Should fail gracefully with helpful error message\n        assert result.exit_code != 0\n        assert 'unsupported' in result.output.lower() or 'invalid' in result.output.lower()\n        \n        # Test file size validation (quickstart.md troubleshooting)\n        # Files must be ≤ 10MB per quickstart.md\n        \n        # Test missing file\n        result = runner.invoke(cli, [\n            'analysis', 'create',\n            '--name', 'Missing File Test',\n            '/nonexistent/file.csv'\n        ])\n        \n        assert result.exit_code != 0\n        assert 'not found' in result.output.lower() or 'no such file' in result.output.lower()\n        \n        # Test workflow step validation (prerequisites)\n        result = runner.invoke(cli, [\n            'analysis', 'create',\n            '--name', 'Step Validation Test',\n            quickstart_vehicle_csv\n        ])\n        \n        if result.exit_code == 0:\n            analysis_data = json.loads(result.output)\n            analysis_id = analysis_data['analysis_id']\n            \n            # Try to skip steps (should fail)\n            result = runner.invoke(cli, [\n                'risks', 'calculate', analysis_id  # Skip asset definition\n            ])\n            \n            # Should fail due to missing prerequisites\n            assert result.exit_code != 0\n            assert 'prerequisite' in result.output.lower() or 'step' in result.output.lower()\n        \n        # Cleanup\n        Path(invalid_file).unlink()\n        Path(quickstart_vehicle_csv).unlink()\n    \n    def test_quickstart_help_system(self, runner):\n        """Test help system per quickstart.md getting help section."""\n        # Test general help (quickstart.md lines 395-409)\n        result = runner.invoke(cli, ['--help'])\n        assert result.exit_code == 0\n        assert 'analysis' in result.output.lower()\n        assert 'export' in result.output.lower()\n        \n        # Test command-specific help\n        result = runner.invoke(cli, ['analysis', 'create', '--help'])\n        assert result.exit_code == 0\n        assert 'name' in result.output.lower()\n        assert 'format' in result.output.lower()\n        \n        # Test system status\n        result = runner.invoke(cli, ['status'])\n        # Should complete successfully or with clear error\n        assert result.exit_code is not None\n        \n        print("✅ Help system validation completed")\n    \n    def test_quickstart_advanced_features(self, runner, quickstart_vehicle_csv):\n        """Test advanced features mentioned in quickstart.md."""\n        # Test batch processing (quickstart.md lines 329-340)\n        analysis_files = []\n        \n        # Create multiple system files\n        for i in range(2):\n            csv_content = f"""Asset Name,Asset Type,Criticality Level,Interfaces,Description\nTest Asset {i},HARDWARE,HIGH,CAN,Test system {i}"""\n            \n            with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:\n                f.write(csv_content)\n                analysis_files.append(f.name)\n        \n        # Test batch analysis creation\n        batch_ids = []\n        \n        for i, file_path in enumerate(analysis_files):\n            result = runner.invoke(cli, [\n                'analysis', 'create',\n                '--name', f'Batch Test {i}',\n                file_path\n            ])\n            \n            if result.exit_code == 0:\n                analysis_data = json.loads(result.output)\n                batch_ids.append(analysis_data['analysis_id'])\n        \n        # Test analysis listing\n        result = runner.invoke(cli, ['analysis', 'list', '--format', 'table'])\n        assert result.exit_code == 0\n        \n        if len(batch_ids) > 0:\n            # Should show created analyses\n            for analysis_id in batch_ids:\n                # May or may not contain full ID (could be truncated in display)\n                pass\n        \n        # Test custom configuration (quickstart.md lines 342-354)\n        config_content = \"\"\"risk_thresholds:\n  low_max: 0.3\n  medium_max: 0.6\n  high_max: 0.8\n  very_high_min: 0.8\"\"\"\n        \n        with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:\n            f.write(config_content)\n            config_file = f.name\n        \n        if len(batch_ids) > 0:\n            # Test custom risk calculation\n            result = runner.invoke(cli, [\n                'risks', 'calculate',\n                '--threshold-config', config_file,\n                batch_ids[0]\n            ])\n            \n            # Should handle custom configuration gracefully\n            # May succeed or fail depending on analysis state\n            assert result.exit_code is not None\n        \n        # Cleanup\n        for file_path in analysis_files:\n            Path(file_path).unlink()\n        Path(config_file).unlink()\n        Path(quickstart_vehicle_csv).unlink()\n        \n        print("✅ Advanced features testing completed")